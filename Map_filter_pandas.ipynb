{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Map_filter_pandas.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP/bAtFxK23mPvcDfo30LnX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vinsilico/INSeq_pipeline/blob/main/Map_filter_pandas.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Upimv1nG8i8i"
      },
      "source": [
        "import collections\n",
        "import os\n",
        "import sys\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import readline\n",
        "#Usage : python script.py inputfile TA_wigfile \n",
        "\n",
        "#Read the files from the command line\n",
        "passed=str(sys.argv)\n",
        "wkdir=os.getcwd()\n",
        "IP_File=wkdir+'/'+str(sys.argv[1])\n",
        "IP_File2=wkdir+'/'+str(sys.argv[2])\n",
        "\n",
        "#print names of input file and TA wig file\n",
        "print (\"File 1:\", IP_File)\n",
        "print (\"File 2:\", IP_File2)\n",
        "\n",
        "bedfile = open(IP_File, 'r')\n",
        "TAfile = open(IP_File2, 'r')\n",
        "subfolders_list=[]\n",
        "subfolders = IP_File.split(\".\")\n",
        "subfoldername = subfolders[0]\n",
        "File_name = subfoldername.split(\"/\")\n",
        "#print (\"File:\", File_name[-1])\n",
        "\n",
        "#Read in the TA coordinate from wig file\n",
        "TA_data=[]\n",
        "for line in TAfile:\n",
        "    items = line.rstrip('\\r\\n').split('\\t')\n",
        "    items = [item.strip() for item in items]\n",
        "    TA_data.append(items)\n",
        "\n",
        "#Read only the T coordinate position into a list\n",
        "TA_data1=open(IP_File2,\"r\")\n",
        "lines=TA_data1.readlines()\n",
        "TA_start=[]\n",
        "for value in lines:\n",
        "    TA_start.append(value.split('\\t')[1])\n",
        "TA_data1.close()\n",
        "\n",
        "#converting the T coordinate from string to integer dType\n",
        "TA_start = list(map(int, TA_start))\n",
        "\n",
        "TA_start_plus = []\n",
        "TA_start_minus = []\n",
        "TA_start_plus = [x+1 for x in TA_start]\n",
        "TA_start_minus = [x-1 for x in TA_start]\n",
        "\n",
        "#Read the input file into a dataframe and add column header\n",
        "datasetB = pd.read_csv(IP_File, sep=\" \", delimiter=\"\\t\",  header=None)\n",
        "datasetB.columns = [\"ID\", \"BC\", \"Rep\",\"Coord\", \"Strand\", \"Col6\", \"Col7\", \"Col8\", \"Col9\", \"COl10\"]\n",
        "\n",
        "#Sort the dataframe by coordinate\n",
        "datasetB = datasetB.sort_values(by=['Coord'])\n",
        "\n",
        "#check for the presence T and T+1 coordinate in the the input file\n",
        "datasetB['F_srt'] = datasetB.Coord.isin(TA_start).astype(int)\n",
        "datasetB['F_srt_p'] = datasetB.Coord.isin(TA_start_plus).astype(int)\n",
        "#datasetB['F_srt_m'] = datasetB.Coord.isin(TA_start_minus).astype(int)\n",
        "\n",
        "#filter \n",
        "datasetG = datasetB.query('F_srt == 1')\n",
        "#datasetH = datasetB.query('F_srt_m == 1')\n",
        "datasetJ = datasetB.query('F_srt_p == 1')\n",
        "\n",
        "#frames = [datasetG,datasetH, datasetJ]\n",
        "frames = [datasetG, datasetJ]\n",
        "datasetK = pd.concat(frames)\n",
        "print(datasetK)\n",
        "#datasetC = datasetK[(datasetK['F_srt'] == 1) | (datasetK['F_srt_p'] == 1) | (datasetK['F_srt_m'] == 1)]\n",
        "datasetC = datasetK[(datasetK['F_srt'] == 1) | (datasetK['F_srt_p'] == 1)]\n",
        "\n",
        "#datasetD = datasetK.drop(columns=['F_srt','F_srt_p','F_srt_m'])\n",
        "datasetD = datasetK.drop(columns=['F_srt','F_srt_p'])\n",
        "\n",
        "datasetC.to_csv(wkdir+'/'+'TA_check-TA-'+File_name[-1]+'.txt', header=False, index=False, sep='\\t')\n",
        "datasetD.to_csv(wkdir+'/'+'TA_filter-TA-'+File_name[-1]+'.txt', header=False, index=False, sep='\\t')\n",
        "print(\"File written\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}